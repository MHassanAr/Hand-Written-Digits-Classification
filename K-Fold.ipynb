{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load MNIST dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combine the training and test sets into one</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.concatenate([X_train, X_test], axis=0)\n",
    "y_combined = np.concatenate([y_train, y_test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalize the images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = X_combined / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Flatten the images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_flattened = X_combined.reshape(len(X_combined), 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initialize the KFold cross-validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Track the metrics for each fold\n",
    "fold_accuracies = []\n",
    "fold_losses = []\n",
    "fold_val_accuracies = []\n",
    "fold_val_losses = []\n",
    "fold_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perform 5-fold cross-validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hassan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5697 - loss: 1.6783 - val_accuracy: 0.8852 - val_loss: 0.5310\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8995 - loss: 0.4428 - val_accuracy: 0.9138 - val_loss: 0.3256\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2952 - val_accuracy: 0.9236 - val_loss: 0.2701\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2396 - val_accuracy: 0.9309 - val_loss: 0.2398\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.2118 - val_accuracy: 0.9356 - val_loss: 0.2246\n",
      "Fold 1 - Training Loss: 0.2093, Training Accuracy: 0.9407\n",
      "Fold 1 - Validation Loss: 0.2246, Validation Accuracy: 0.9356\n",
      "Time taken for Fold 1: 24.03 seconds\n",
      "\n",
      "Training on Fold 2...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5681 - loss: 1.6164 - val_accuracy: 0.8717 - val_loss: 0.5833\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8891 - loss: 0.4847 - val_accuracy: 0.9026 - val_loss: 0.3596\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.3162 - val_accuracy: 0.9201 - val_loss: 0.2887\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2584 - val_accuracy: 0.9264 - val_loss: 0.2548\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.2296 - val_accuracy: 0.9307 - val_loss: 0.2370\n",
      "Fold 2 - Training Loss: 0.2262, Training Accuracy: 0.9349\n",
      "Fold 2 - Validation Loss: 0.2370, Validation Accuracy: 0.9307\n",
      "Time taken for Fold 2: 29.64 seconds\n",
      "\n",
      "Training on Fold 3...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5523 - loss: 1.6245 - val_accuracy: 0.8692 - val_loss: 0.5488\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.4829 - val_accuracy: 0.9024 - val_loss: 0.3562\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.3357 - val_accuracy: 0.9209 - val_loss: 0.2883\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2721 - val_accuracy: 0.9289 - val_loss: 0.2528\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.2372 - val_accuracy: 0.9323 - val_loss: 0.2344\n",
      "Fold 3 - Training Loss: 0.2293, Training Accuracy: 0.9364\n",
      "Fold 3 - Validation Loss: 0.2344, Validation Accuracy: 0.9323\n",
      "Time taken for Fold 3: 25.60 seconds\n",
      "\n",
      "Training on Fold 4...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5530 - loss: 1.6646 - val_accuracy: 0.8707 - val_loss: 0.5612\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8825 - loss: 0.4833 - val_accuracy: 0.9086 - val_loss: 0.3487\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.3083 - val_accuracy: 0.9226 - val_loss: 0.2799\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2610 - val_accuracy: 0.9275 - val_loss: 0.2493\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2285 - val_accuracy: 0.9333 - val_loss: 0.2285\n",
      "Fold 4 - Training Loss: 0.2219, Training Accuracy: 0.9370\n",
      "Fold 4 - Validation Loss: 0.2285, Validation Accuracy: 0.9333\n",
      "Time taken for Fold 4: 24.52 seconds\n",
      "\n",
      "Training on Fold 5...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5986 - loss: 1.6212 - val_accuracy: 0.8718 - val_loss: 0.5516\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.4755 - val_accuracy: 0.9070 - val_loss: 0.3488\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.3293 - val_accuracy: 0.9186 - val_loss: 0.2900\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2739 - val_accuracy: 0.9261 - val_loss: 0.2614\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2450 - val_accuracy: 0.9341 - val_loss: 0.2405\n",
      "Fold 5 - Training Loss: 0.2405, Training Accuracy: 0.9327\n",
      "Fold 5 - Validation Loss: 0.2405, Validation Accuracy: 0.9341\n",
      "Time taken for Fold 5: 24.10 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_combined_flattened, y_combined)):\n",
    "    print(f\"Training on Fold {fold + 1}...\")\n",
    "    \n",
    "    # Split data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_combined_flattened[train_idx], X_combined_flattened[val_idx]\n",
    "    y_train_fold, y_val_fold = y_combined[train_idx], y_combined[val_idx]\n",
    "    \n",
    "    # Build the model \n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, input_shape=(784,), activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(16, activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\"),  \n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Track the time before training starts\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model on the current fold, specifying validation data for validation metrics\n",
    "    history = model.fit(X_train_fold, y_train_fold, epochs=5, batch_size=32, validation_data=(X_val_fold, y_val_fold), verbose=1)\n",
    "    \n",
    "    # Track the time taken for training\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    # Evaluate the model on the validation set of the current fold\n",
    "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    \n",
    "    # Extract training loss and accuracy from history\n",
    "    train_loss = history.history['loss'][-1]  \n",
    "    train_accuracy = history.history['accuracy'][-1]  \n",
    "    \n",
    "    # Append the results\n",
    "    fold_accuracies.append(train_accuracy)\n",
    "    fold_losses.append(train_loss)\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    fold_val_losses.append(val_loss)\n",
    "    fold_times.append(time_taken)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Time taken for Fold {fold + 1}: {time_taken:.2f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculate the average accuracy and loss across all folds</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy: 0.9363\n",
      "Average Training Loss: 0.2254\n",
      "Average Validation Accuracy: 0.9332\n",
      "Average Validation Loss: 0.2330\n",
      "Average Time per Fold: 25.58 seconds\n"
     ]
    }
   ],
   "source": [
    "avg_train_accuracy = np.mean(fold_accuracies)\n",
    "avg_train_loss = np.mean(fold_losses)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "avg_val_loss = np.mean(fold_val_losses)\n",
    "avg_time = np.mean(fold_times)\n",
    "\n",
    "print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Average Time per Fold: {avg_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using 'kullback_leibler_divergence' loss function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold 1...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1559 - loss: 0.1503 - val_accuracy: 0.0959 - val_loss: 0.0026\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0994 - loss: 0.0017 - val_accuracy: 0.0959 - val_loss: 5.3152e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 4.0467e-04 - val_accuracy: 0.0959 - val_loss: 1.7102e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0982 - loss: 1.3298e-04 - val_accuracy: 0.0959 - val_loss: 5.7335e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1005 - loss: 4.3421e-05 - val_accuracy: 0.0986 - val_loss: 1.4661e-05\n",
      "Fold 1 - Training Loss: 0.0000, Training Accuracy: 0.1004\n",
      "Fold 1 - Validation Loss: 0.0000, Validation Accuracy: 0.0986\n",
      "Time taken for Fold 1: 32.92 seconds\n",
      "\n",
      "Training on Fold 2...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1679 - loss: 0.2133 - val_accuracy: 0.2026 - val_loss: 0.0030\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1954 - loss: 0.0020 - val_accuracy: 0.2033 - val_loss: 5.8882e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1625 - loss: 4.4753e-04 - val_accuracy: 0.1059 - val_loss: 1.8074e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1016 - loss: 1.4202e-04 - val_accuracy: 0.1059 - val_loss: 5.9812e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.1058 - loss: 4.5832e-05 - val_accuracy: 0.1059 - val_loss: 1.5458e-05\n",
      "Fold 2 - Training Loss: 0.0000, Training Accuracy: 0.1038\n",
      "Fold 2 - Validation Loss: 0.0000, Validation Accuracy: 0.1059\n",
      "Time taken for Fold 2: 44.37 seconds\n",
      "\n",
      "Training on Fold 3...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 0.1912 - val_accuracy: 0.0991 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1006 - loss: 0.0022 - val_accuracy: 0.0991 - val_loss: 7.4295e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1017 - loss: 5.7175e-04 - val_accuracy: 0.0991 - val_loss: 2.4836e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1017 - loss: 1.9568e-04 - val_accuracy: 0.0991 - val_loss: 8.7769e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.0997 - loss: 6.8137e-05 - val_accuracy: 0.0991 - val_loss: 2.7034e-05\n",
      "Fold 3 - Training Loss: 0.0001, Training Accuracy: 0.1000\n",
      "Fold 3 - Validation Loss: 0.0000, Validation Accuracy: 0.0991\n",
      "Time taken for Fold 3: 42.27 seconds\n",
      "\n",
      "Training on Fold 4...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 0.1790 - val_accuracy: 0.0987 - val_loss: 0.0032\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1004 - loss: 0.0021 - val_accuracy: 0.0987 - val_loss: 6.6940e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.1016 - loss: 5.1487e-04 - val_accuracy: 0.0987 - val_loss: 2.1733e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 1.7170e-04 - val_accuracy: 0.0987 - val_loss: 7.5190e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1002 - loss: 5.8560e-05 - val_accuracy: 0.0987 - val_loss: 2.1896e-05\n",
      "Fold 4 - Training Loss: 0.0000, Training Accuracy: 0.1001\n",
      "Fold 4 - Validation Loss: 0.0000, Validation Accuracy: 0.0987\n",
      "Time taken for Fold 4: 34.67 seconds\n",
      "\n",
      "Training on Fold 5...\n",
      "Epoch 1/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1082 - loss: 0.1592 - val_accuracy: 0.1010 - val_loss: 0.0029\n",
      "Epoch 2/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1032 - loss: 0.0020 - val_accuracy: 0.1010 - val_loss: 5.9697e-04\n",
      "Epoch 3/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 4.5396e-04 - val_accuracy: 0.1010 - val_loss: 1.8836e-04\n",
      "Epoch 4/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1035 - loss: 1.4736e-04 - val_accuracy: 0.1010 - val_loss: 6.3478e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1019 - loss: 4.8681e-05 - val_accuracy: 0.1010 - val_loss: 1.7057e-05\n",
      "Fold 5 - Training Loss: 0.0000, Training Accuracy: 0.1023\n",
      "Fold 5 - Validation Loss: 0.0000, Validation Accuracy: 0.1010\n",
      "Time taken for Fold 5: 23.47 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_combined_flattened, y_combined)):\n",
    "    print(f\"Training on Fold {fold + 1}...\")\n",
    "    \n",
    "    # Split data into training and validation sets for the current fold\n",
    "    X_train_fold, X_val_fold = X_combined_flattened[train_idx], X_combined_flattened[val_idx]\n",
    "    y_train_fold, y_val_fold = y_combined[train_idx], y_combined[val_idx]\n",
    "    \n",
    "    # One-hot encode the labels for KL Divergence\n",
    "    y_train_fold_one_hot = keras.utils.to_categorical(y_train_fold, 10)\n",
    "    y_val_fold_one_hot = keras.utils.to_categorical(y_val_fold, 10)\n",
    "    \n",
    "    # Build the model (you can modify the architecture here if needed)\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, input_shape=(784,), activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(16, activation=\"sigmoid\"),\n",
    "        keras.layers.Dense(10, activation=\"sigmoid\"),  \n",
    "    ])\n",
    "    \n",
    "    # Compile the model using Kullback-Leibler Divergence as the loss function\n",
    "    model.compile(optimizer=\"adam\", loss=tf.keras.losses.KLDivergence(), metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Track the time before training starts\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model on the current fold, specifying validation data for validation metrics\n",
    "    history = model.fit(X_train_fold, y_train_fold_one_hot, epochs=5, batch_size=32, validation_data=(X_val_fold, y_val_fold_one_hot), verbose=1)\n",
    "    \n",
    "    # Track the time taken for training\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    # Evaluate the model on the validation set of the current fold\n",
    "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold_one_hot, verbose=0)\n",
    "    \n",
    "    # Extract training loss and accuracy from history\n",
    "    train_loss = history.history['loss'][-1]  # Last epoch training loss\n",
    "    train_accuracy = history.history['accuracy'][-1]  # Last epoch training accuracy\n",
    "    \n",
    "    # Append the results\n",
    "    fold_accuracies.append(train_accuracy)\n",
    "    fold_losses.append(train_loss)\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    fold_val_losses.append(val_loss)\n",
    "    fold_times.append(time_taken)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Fold {fold + 1} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Time taken for Fold {fold + 1}: {time_taken:.2f} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy: 0.5178\n",
      "Average Training Loss: 0.1171\n",
      "Average Validation Accuracy: 0.5163\n",
      "Average Validation Loss: 0.1207\n",
      "Average Time per Fold: 37.49 seconds\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the average metrics across all folds\n",
    "avg_train_accuracy = np.mean(fold_accuracies)\n",
    "avg_train_loss = np.mean(fold_losses)\n",
    "avg_val_accuracy = np.mean(fold_val_accuracies)\n",
    "avg_val_loss = np.mean(fold_val_losses)\n",
    "avg_time = np.mean(fold_times)\n",
    "\n",
    "print(f\"Average Training Accuracy: {avg_train_accuracy:.4f}\")\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "print(f\"Average Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Average Time per Fold: {avg_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
